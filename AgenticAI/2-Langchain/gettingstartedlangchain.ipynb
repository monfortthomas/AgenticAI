{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7ae95606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8f3c76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic2.0'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4dd7e631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a95342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47124a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000206C5314A90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000206C65DC610> root_client=<openai.OpenAI object at 0x00000206C42AD010> root_async_client=<openai.AsyncOpenAI object at 0x00000206C5317790> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35ca146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Agentic AI** refers to artificial intelligence systems designed with a degree of agency, meaning they possess the capacity to act autonomously, make decisions, set goals, and adapt their behavior based on interactions with their environment. Unlike traditional AI systems that strictly follow predefined instructions or operate within narrow parameters, agentic AI exhibits characteristics akin to independent agents capable of pursuing objectives with minimal human intervention.\\n\\n### Key Characteristics of Agentic AI\\n\\n1. **Autonomy**: Agentic AI can operate independently without constant human supervision. It can initiate actions, respond to changes, and manage tasks on its own.\\n\\n2. **Goal-Oriented Behavior**: These AI systems can set, prioritize, and pursue goals. They can adjust their objectives based on new information or shifting circumstances.\\n\\n3. **Decision-Making Capabilities**: Agentic AI can evaluate options, weigh outcomes, and make choices based on predefined criteria or learned experiences.\\n\\n4. **Adaptability and Learning**: They can learn from interactions, experiences, and data to improve performance, adapt to new situations, and refine strategies over time.\\n\\n5. **Interactive and Responsive**: They can engage with their environment and other systems or users, responding dynamically to inputs and feedback.\\n\\n### Applications of Agentic AI\\n\\n- **Autonomous Vehicles**: Self-driving cars navigate traffic, make real-time decisions, and adapt to road conditions without human input.\\n  \\n- **Advanced Robotics**: Robots in manufacturing, healthcare, or service industries can perform complex tasks, adapt to new processes, and collaborate with humans.\\n\\n- **Virtual Personal Assistants**: Enhanced AI assistants can manage schedules, make recommendations, and proactively handle tasks based on user behavior and preferences.\\n\\n- **Smart Infrastructure**: Systems managing energy grids, transportation networks, or urban planning can optimize operations and respond to changing demands autonomously.\\n\\n### Ethical and Safety Considerations\\n\\nThe development of agentic AI introduces several important considerations:\\n\\n- **Alignment with Human Values**: Ensuring that autonomous actions align with ethical standards and societal norms to prevent unintended harmful outcomes.\\n  \\n- **Accountability**: Determining responsibility for decisions made by autonomous AI systems, especially in critical applications like healthcare or autonomous weapons.\\n\\n- **Transparency**: Making the decision-making processes of agentic AI understandable to humans to build trust and facilitate oversight.\\n\\n- **Control Mechanisms**: Implementing fail-safes and control protocols to manage or override AI actions if they deviate from desired behavior.\\n\\n### Current Research and Development\\n\\nResearch in agentic AI spans multiple disciplines, including machine learning, cognitive science, robotics, and ethics. Efforts are focused on enhancing the decision-making capabilities of AI, improving adaptability through advanced learning algorithms, and establishing frameworks to ensure safe and ethical autonomous behavior.\\n\\n### Conclusion\\n\\nAgentic AI represents a significant advancement in artificial intelligence, moving beyond task-specific automation to systems that can act with a degree of independence and purpose. As this technology progresses, it promises to revolutionize various sectors by enabling more efficient, responsive, and intelligent operations. However, it also necessitates careful consideration of ethical, safety, and societal impacts to ensure that the benefits of agentic AI are realized responsibly.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1158, 'prompt_tokens': 13, 'total_tokens': 1171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_7989eaacf6', 'id': 'chatcmpl-Balrdb2sfRcafLQJsyBDrb4PiTE1E', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--4eb5e626-1f5d-448d-a3c9-b49a3a8f4628-0' usage_metadata={'input_tokens': 13, 'output_tokens': 1158, 'total_tokens': 1171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Agentic AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "41d6b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems designed with a degree of agency, meaning they possess the capacity to act autonomously, make decisions, set goals, and adapt their behavior based on interactions with their environment. Unlike traditional AI systems that strictly follow predefined instructions or operate within narrow parameters, agentic AI exhibits characteristics akin to independent agents capable of pursuing objectives with minimal human intervention.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Autonomy**: Agentic AI can operate independently without constant human supervision. It can initiate actions, respond to changes, and manage tasks on its own.\n",
      "\n",
      "2. **Goal-Oriented Behavior**: These AI systems can set, prioritize, and pursue goals. They can adjust their objectives based on new information or shifting circumstances.\n",
      "\n",
      "3. **Decision-Making Capabilities**: Agentic AI can evaluate options, weigh outcomes, and make choices based on predefined criteria or learned experiences.\n",
      "\n",
      "4. **Adaptability and Learning**: They can learn from interactions, experiences, and data to improve performance, adapt to new situations, and refine strategies over time.\n",
      "\n",
      "5. **Interactive and Responsive**: They can engage with their environment and other systems or users, responding dynamically to inputs and feedback.\n",
      "\n",
      "### Applications of Agentic AI\n",
      "\n",
      "- **Autonomous Vehicles**: Self-driving cars navigate traffic, make real-time decisions, and adapt to road conditions without human input.\n",
      "  \n",
      "- **Advanced Robotics**: Robots in manufacturing, healthcare, or service industries can perform complex tasks, adapt to new processes, and collaborate with humans.\n",
      "\n",
      "- **Virtual Personal Assistants**: Enhanced AI assistants can manage schedules, make recommendations, and proactively handle tasks based on user behavior and preferences.\n",
      "\n",
      "- **Smart Infrastructure**: Systems managing energy grids, transportation networks, or urban planning can optimize operations and respond to changing demands autonomously.\n",
      "\n",
      "### Ethical and Safety Considerations\n",
      "\n",
      "The development of agentic AI introduces several important considerations:\n",
      "\n",
      "- **Alignment with Human Values**: Ensuring that autonomous actions align with ethical standards and societal norms to prevent unintended harmful outcomes.\n",
      "  \n",
      "- **Accountability**: Determining responsibility for decisions made by autonomous AI systems, especially in critical applications like healthcare or autonomous weapons.\n",
      "\n",
      "- **Transparency**: Making the decision-making processes of agentic AI understandable to humans to build trust and facilitate oversight.\n",
      "\n",
      "- **Control Mechanisms**: Implementing fail-safes and control protocols to manage or override AI actions if they deviate from desired behavior.\n",
      "\n",
      "### Current Research and Development\n",
      "\n",
      "Research in agentic AI spans multiple disciplines, including machine learning, cognitive science, robotics, and ethics. Efforts are focused on enhancing the decision-making capabilities of AI, improving adaptability through advanced learning algorithms, and establishing frameworks to ensure safe and ethical autonomous behavior.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Agentic AI represents a significant advancement in artificial intelligence, moving beyond task-specific automation to systems that can act with a degree of independence and purpose. As this technology progresses, it promises to revolutionize various sectors by enabling more efficient, responsive, and intelligent operations. However, it also necessitates careful consideration of ethical, safety, and societal impacts to ensure that the benefits of agentic AI are realized responsibly.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8357dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user introduced themselves as Krish. I should respond politely and maybe ask how I can assist them today. Let me check the guidelines to make sure I follow the correct tone and structure. Keep it friendly and open-ended so Krish feels comfortable to ask for help. Maybe something like, \"Hi Krish! How can I assist you today?\" That should work. I don\\'t need any markdown here, just a simple, friendly message.\\n</think>\\n\\nHi Krish! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 15, 'total_tokens': 118, 'completion_time': 0.25681602, 'prompt_time': 0.003608816, 'queue_time': 0.803704855, 'total_time': 0.260424836}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'stop', 'logprobs': None}, id='run--69e54353-7605-4965-b5e3-820fade808c0-0', usage_metadata={'input_tokens': 15, 'output_tokens': 103, 'total_tokens': 118})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "model.invoke(\"Hi My name is Krish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "88e170b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8d414adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000206C52DA310>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000206C65E0B90>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2d40b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000206C52DA310>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000206C65E0B90>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chaining\n",
    "chain=prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7a293571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I can definitely tell you about Langsmith! \n",
      "\n",
      "Langsmith is an open-source framework developed by the Gemma team at Google DeepMind. It's designed to simplify the process of fine-tuning large language models (LLMs) for specific tasks. \n",
      "\n",
      "Here's a breakdown of what makes Langsmith interesting:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **User-Friendly Interface:** Langsmith provides a streamlined web interface that makes it easier for users without extensive coding experience to fine-tune LLMs.\n",
      "* **Modular Design:** It's built with a modular architecture, allowing you to easily swap out different components like datasets, training algorithms, and evaluation metrics.\n",
      "* **Efficient Training:** Langsmith incorporates techniques to optimize the training process, making it more efficient and resource-friendly.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Accessibility:** By lowering the barrier to entry for fine-tuning, Langsmith democratizes access to powerful AI capabilities.\n",
      "* **Customization:**  You can tailor LLMs to your specific needs by fine-tuning them on your own datasets.\n",
      "* **Experimentation:** The modular design encourages exploration and experimentation with different training approaches.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "* **Text Generation:** Fine-tune LLMs for tasks like creative writing, summarization, dialogue generation, and code writing.\n",
      "* **Question Answering:** Train LLMs to answer questions accurately based on specific domains or knowledge bases.\n",
      "* **Translation:** Adapt LLMs for more accurate and context-aware translations.\n",
      "\n",
      "**Getting Started:**\n",
      "\n",
      "You can find more information and documentation about Langsmith on the official GitHub repository: [https://github.com/google-deepmind/langsmith](https://github.com/google-deepmind/langsmith)\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have any other questions about Langsmith or any other AI topics!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"Can you tell me something about Langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6694a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're asking about Langsmith, a powerful tool gaining traction in the AI community.  Here's a breakdown of what you need to know:\n",
      "\n",
      "**What is Langsmith?**\n",
      "\n",
      "Langsmith is an open-source platform designed to simplify and streamline the process of building and deploying large language models (LLMs). Think of it as a specialized workbench for AI developers.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Modular Design:** Langsmith breaks down the LLM development process into manageable components, making it easier to experiment and iterate.\n",
      "* **Simplified Training:** It provides tools and utilities that make training LLMs more accessible, even for developers without extensive machine learning expertise.\n",
      "* **Fine-tuning Capabilities:** Langsmith excels at fine-tuning pre-trained LLMs for specific tasks, allowing you to customize their behavior and performance.\n",
      "* **Integration Ecosystem:** It seamlessly integrates with popular frameworks like Transformers and Hugging Face, leveraging existing resources and communities.\n",
      "* **Deployment Flexibility:** Langsmith supports various deployment options, including on-premise servers, cloud platforms, and even directly within applications.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Faster Development Cycles:** By abstracting away complexity, Langsmith accelerates the time it takes to bring AI models to life.\n",
      "* **Reduced Entry Barrier:** It empowers developers with less machine learning experience to contribute to the field of LLMs.\n",
      "* **Cost-Effectiveness:**  Langsmith's modularity and fine-tuning capabilities can help optimize resource usage and reduce training costs.\n",
      "* **Community-Driven Innovation:** Being open-source, Langsmith benefits from the contributions and feedback of a vibrant community of developers.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "Langsmith's versatility finds applications in a wide range of domains:\n",
      "\n",
      "* **Chatbots and Conversational AI:**  Building intelligent chatbots for customer service, education, or entertainment.\n",
      "* **Text Summarization and Generation:**  Creating concise summaries of documents or generating creative text formats.\n",
      "* **Code Generation and Assistance:**  Assisting developers with code completion, documentation, and bug detection.\n",
      "* **Data Analysis and Insights:**  Extracting valuable insights from large datasets through natural language processing.\n",
      "\n",
      "**Getting Started:**\n",
      "\n",
      "If you're interested in exploring Langsmith, its documentation and community resources are excellent starting points. The open-source nature of the platform encourages experimentation and collaboration, making it a valuable tool for both beginners and experienced AI developers.\n",
      "\n",
      "\n",
      "Let me know if you have any more specific questions about Langsmith!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0221a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66da8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5fe079e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "52a5b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'LangSmith', 'description': 'LangSmith is an open-source platform for building and deploying large language models (LLMs).', 'features': ['Fine-tuning existing LLMs', 'Training custom LLMs from scratch', 'Evaluating and benchmarking LLMs', 'Deploying LLMs as APIs', 'Collaborative development and community support'], 'website': 'https://github.com/google/langsmith', 'key_benefits': ['Accessibility: Makes LLM development accessible to a wider audience.', 'Transparency: Open-source nature allows for scrutiny and collaboration.', 'Flexibility: Supports various training methods and model architectures.', 'Efficiency: Streamlines the LLM development workflow.']}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7ee96082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Assisgnment ---Chatprompttemplate\n",
    "\n",
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ed7d7e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': \"Langsmith is an open-source tool designed to simplify the process of developing and deploying language models. \\n\\nHere are some key aspects of Langsmith:\\n\\n* **Ease of Use:** It provides a user-friendly interface that makes it accessible to both beginners and experienced developers.\\n\\n* **Streamlined Workflow:** Langsmith streamlines the entire machine learning workflow, from data preparation and model training to evaluation and deployment.\\n\\n* **Open-Weight Models:** It encourages the use of open-weight models, making AI more transparent and accessible to the wider community.\\n\\n* **Community Driven:** Langsmith is developed and maintained by a community of contributors, fostering collaboration and innovation.\\n\\n* **Integration with Tools:** It integrates well with popular machine learning frameworks and tools, allowing developers to leverage existing resources.\\n\\n**Key Features:**\\n\\n* **Data Management:** Tools for data loading, preprocessing, and splitting.\\n* **Model Training:** Support for training various types of language models.\\n* **Hyperparameter Tuning:** Automated techniques for finding optimal model settings.\\n* **Model Evaluation:** Metrics and visualizations to assess model performance.\\n* **Model Deployment:** Options for deploying models as APIs or web applications.\\n\\n**Benefits:**\\n\\n* **Reduced Development Time:** \\nLangsmith's streamlined workflow accelerates the development process.\\n* **Improved Accessibility:**  Makes AI development more accessible to a broader audience.\\n* **Increased Transparency:**  The use of open-weight models promotes transparency and trust.\\n* **Enhanced Collaboration:**  Community-driven development fosters innovation and knowledge sharing.\"}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50822936",
   "metadata": {},
   "source": [
    "### Assigments: https://python.langchain.com/docs/how_to/#prompt-templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0c1c1802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0ca6e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "940f704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```xml\\n<response>\\n  <description>Langsmith is an open-source platform for building and deploying large language models (LLMs). It provides a comprehensive set of tools and resources for the entire LLM lifecycle, from training and evaluation to deployment and monitoring.</description>\\n  <features>\\n    <feature>Supports various LLM architectures, including transformer-based models like GPT and T5.</feature>\\n    <feature>Offers a user-friendly interface for managing datasets, training jobs, and model deployments.</feature>\\n    <feature>Provides built-in tools for evaluating model performance and identifying areas for improvement.</feature>\\n    <feature>Enables easy integration with other machine learning tools and platforms.</feature>\\n  </features>\\n  <benefits>\\n    <benefit>Accelerates the development and deployment of custom LLMs.</benefit>\\n    <benefit>Reduces the cost and complexity of LLM development.</benefit>\\n    <benefit>Provides a collaborative environment for LLM research and development.</benefit>\\n  </benefits>\\n</response>\\n``` \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 229, 'prompt_tokens': 195, 'total_tokens': 424, 'completion_time': 0.416363636, 'prompt_time': 0.009220491, 'queue_time': 0.245043897, 'total_time': 0.425584127}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--c1614b65-ffed-4b7c-897e-edb58b5e243f-0' usage_metadata={'input_tokens': 195, 'output_tokens': 229, 'total_tokens': 424}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1eec50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response><answer>LangChain is a framework for developing applications powered by large language models (LLMs). It provides tools and building blocks for chaining together different components, such as LLMs, databases, APIs, and other AI services, to create more complex and powerful applications. </answer></response> \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 39, 'total_tokens': 104, 'completion_time': 0.118181818, 'prompt_time': 0.002368596, 'queue_time': 0.246233862, 'total_time': 0.120550414}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--6624b9e7-180f-431a-8796-10d7eb02f894-0' usage_metadata={'input_tokens': 39, 'output_tokens': 65, 'total_tokens': 104}\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "#from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ab7431f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle find its way home?\",\n",
       " 'punchline': 'Because it lost its bearings!'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "36e1dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why couldn't the bicycle stand up by itself? Because it was two tired!\"}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8f2ec0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<movie>Big</movie>\n",
      "<movie>Saving Private Ryan</movie>\n",
      "<movie>Forrest Gump</movie>\n",
      "<movie>Apollo 13</movie>\n",
      "<movie>Cast Away</movie>\n",
      "<movie>The Green Mile</movie>\n",
      "<movie>Toy Story</movie>\n",
      "<movie>Philadelphia</movie>\n",
      "<movie>Sully</movie>\n",
      "<movie>Bridge of Spies</movie>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c90caccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why couldn't the bicycle stand up by itself?\", punchline='Because it was two tired!')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfed2d4",
   "metadata": {},
   "source": [
    "### Assisgment:\n",
    "Create a simple assistant that uses any LLM and should be pydantic, when we ask about any product it should give you two information product Name, product details tentative price in USD (integer). use chat Prompt Template.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "60f7193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Product': 'OnePlus latest model', 'ProductDetails': 'OnePlus latest model is the OnePlus 9 Pro, featuring a 6.7-inch Fluid AMOLED display, Snapdragon 888 processor, quad-camera setup with Hasselblad collaboration, and 5G connectivity.', 'Productprice': '$969.00', 'currency': 'USD'}\n"
     ]
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from decimal import Decimal\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class product(BaseModel):\n",
    "    product: str = Field(description=\"Name of a product\")\n",
    "    productDetails: str = Field(description=\"Details of a product\")\n",
    "    productprice: Decimal = Field(description=\"Price of a product\")\n",
    "    currency: str = Field(default=\"USD\", description=\"Currency of the product price\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "product_query = \"what is the price of one plus latest model?\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=product)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Provide details about the following product, details and price:\\n{query}\\nFormat the output as JSON.\",\n",
    "    input_variables=[\"query\"],\n",
    "    output_parser=parser\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "response = chain.invoke({\"query\": product_query})\n",
    "\n",
    "corrected_response = {\n",
    "    \"Product\": response.get(\"product\"),\n",
    "    \"ProductDetails\": response.get(\"details\"),\n",
    "    \"Productprice\": response.get(\"price\"),\n",
    "    \"currency\": \"USD\"  # Default currency\n",
    "}\n",
    "\n",
    "print(corrected_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e630aa22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd78bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_2_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
